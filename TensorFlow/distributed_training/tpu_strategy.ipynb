{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tpu_strategy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwT0qJClDYBN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import numpy as np"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wihH-JNKAV6u",
        "outputId": "0ea3c000-51ec-4cd8-ddb4-46b599d7395e"
      },
      "source": [
        "#Detect hardware\n",
        "try:\n",
        "  tpu_address = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print(\"Running on TPU \", tpu.cluster_spec().as_dict()['worker'])\n",
        "  print(\"Number of accelerator \", strategy.num_replicas_in_sync)\n",
        "except ValueError:\n",
        "  print(\"TPU failed to initialize\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.88.214.234:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.88.214.234:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.88.214.234:8470']\n",
            "Number of accelerator  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI8_eqtFByWc"
      },
      "source": [
        "SIZE = 224\n",
        "IMAGE_SIZE = [SIZE, SIZE]\n",
        "GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-{}x{}/*.tfrec'.format(IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
        "BATCH_SIZE = 128\n",
        "filenames = tf.io.gfile.glob(GCS_PATTERN)\n",
        "random.shuffle(filenames)\n",
        "VALIDATION_SPLIT = 0.2\n",
        "split = int(len(filenames) * VALIDATION_SPLIT)\n",
        "training_filenames = filenames[split:]\n",
        "testing_filenames = filenames[:split]\n",
        "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "def read_tfrecord(example):\n",
        "  features = {\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"one_hot_class\": tf.io.VarLenFeature(tf.float32)\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  image = example['image']\n",
        "  class_label = example['class']\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "  class_label = tf.cast(class_label, tf.int32)\n",
        "  return image, class_label\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic=False\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  return dataset\n",
        "\n",
        "def get_batched_dataset(filenames):\n",
        "  dataset =  load_dataset(filenames)\n",
        "  dataset = dataset.shuffle(2048)\n",
        "  dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "  return dataset\n",
        "\n",
        "#Distribute dataset using strategy\n",
        "\n",
        "def get_training_data(filenames):\n",
        "  dataset = get_batched_dataset(training_filenames)\n",
        "  dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "  return dataset\n",
        "\n",
        "def get_testing_data(filenames):\n",
        "  dataset = get_batched_dataset(testing_filenames)\n",
        "  dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "  return dataset"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "9qoNkAXgnVPb",
        "outputId": "7f4227cd-585f-4936-c0af-7eaa4f75e439"
      },
      "source": [
        "'''\n",
        "(train_image, train_label), (test_image, test_label) = fashion_mnist.load_data()\n",
        "train_image = train_image / 255.0\n",
        "train_image = np.expand_dims(train_image, axis=-1)\n",
        "test_image = test_image/255.0\n",
        "test_image = np.expand_dims(test_image, axis=-1)\n",
        "train_label = tf.keras.utils.to_categorical(train_label, 10)\n",
        "test_label = tf.keras.utils.to_categorical(test_label, 10)\n",
        "batch_size = 128\n",
        "#Train image\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_image, train_label))\n",
        "train_dataset = train_dataset.shuffle(20180)\n",
        "train_dataset = train_dataset.batch(batch_size*strategy.num_replicas_in_sync, drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(AUTO)\n",
        "train_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "#Test image\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_image, test_label))\n",
        "test_dataset = test_dataset.batch(batch_size*strategy.num_replicas_in_sync, drop_remainder=True)\n",
        "test_dataset = test_dataset.prefetch(AUTO)\n",
        "test_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
        "'''"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n(train_image, train_label), (test_image, test_label) = fashion_mnist.load_data()\\ntrain_image = train_image / 255.0\\ntrain_image = np.expand_dims(train_image, axis=-1)\\ntest_image = test_image/255.0\\ntest_image = np.expand_dims(test_image, axis=-1)\\ntrain_label = tf.keras.utils.to_categorical(train_label, 10)\\ntest_label = tf.keras.utils.to_categorical(test_label, 10)\\nbatch_size = 128\\n#Train image\\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_image, train_label))\\ntrain_dataset = train_dataset.shuffle(20180)\\ntrain_dataset = train_dataset.batch(batch_size*strategy.num_replicas_in_sync, drop_remainder=True)\\ntrain_dataset = train_dataset.prefetch(AUTO)\\ntrain_dataset = strategy.experimental_distribute_dataset(train_dataset)\\n#Test image\\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_image, test_label))\\ntest_dataset = test_dataset.batch(batch_size*strategy.num_replicas_in_sync, drop_remainder=True)\\ntest_dataset = test_dataset.prefetch(AUTO)\\ntest_dataset = strategy.experimental_distribute_dataset(test_dataset)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFiqTPgVAQZL"
      },
      "source": [
        "## Define custome model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq9LtpTH-D9w"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3))\n",
        "    self.maxpool1 = tf.keras.layers.MaxPool2D(2,2)\n",
        "    self.conv2 = tf.keras.layers.Conv2D(64, (3,3), activation='relu')\n",
        "    self.maxpool2 = tf.keras.layers.MaxPool2D(2,2)\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "    self.out = tf.keras.layers.Dense(10, activation='softmax')\n",
        "  def call(self, inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Por4OWS0tWDr"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = MyModel()\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='training_accuracy')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='testing_accuracy')\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  def compute_loss(labels, predictions):\n",
        "    per_example_loss = loss_object(labels, predictions)\n",
        "    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=batch_size*strategy.num_replicas_in_sync)\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "  #Define train function\n",
        "  \n",
        "  #Distribute train and test steps\n",
        "  @tf.function\n",
        "  def distributed_train_step(dataset_inputs):\n",
        "    per_replica_loss = strategy.run(train_steps, args=(dataset_inputs,))\n",
        "    print(per_replica_loss)\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
        "  @tf.function\n",
        "  def distributed_test_steps(dataset_inputs):\n",
        "    strategy.run(test_steps, args=(dataset_inputs,))\n",
        "\n",
        "  def train_steps(inputs):\n",
        "    image, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(image)\n",
        "      loss = compute_loss(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_accuracy.update_state(labels, predictions)\n",
        "    return loss\n",
        "  def test_steps(inputs):\n",
        "    image, labels = inputs\n",
        "    predictions = model(image)\n",
        "    loss = loss_object(labels, predictions)\n",
        "\n",
        "    test_accuracy.update_state(labels, predictions)\n",
        "    test_loss.update_state(loss)\n",
        "    return loss"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UycxBA5RPM4",
        "outputId": "8954f46f-7522-4c48-97cf-b6c6a80bdc0a"
      },
      "source": [
        "EPOCHS = 10\n",
        "with strategy.scope():\n",
        "  for epoch in range(EPOCHS):\n",
        "    #Train Loop\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for x in get_training_data(training_filenames):\n",
        "      total_loss += distributed_train_step(x)\n",
        "      num_batches += 1\n",
        "    train_loss = total_loss / num_batches\n",
        "\n",
        "    #Testing Loop\n",
        "    for x in get_testing_data(testing_filenames):\n",
        "      distributed_test_steps(x)\n",
        "    print(train_loss)\n",
        "\n",
        "    test_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n",
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n",
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n",
            "tf.Tensor(0.34757748, shape=(), dtype=float32)\n",
            "tf.Tensor(0.14548536, shape=(), dtype=float32)\n",
            "tf.Tensor(0.12130156, shape=(), dtype=float32)\n",
            "tf.Tensor(0.09284541, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06476741, shape=(), dtype=float32)\n",
            "tf.Tensor(0.039938573, shape=(), dtype=float32)\n",
            "tf.Tensor(0.021844609, shape=(), dtype=float32)\n",
            "tf.Tensor(0.012696597, shape=(), dtype=float32)\n",
            "tf.Tensor(0.007192103, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0033689819, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heVocU2voqWh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}